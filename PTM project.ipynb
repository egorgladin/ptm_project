{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# import artm\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "# from collections import Counter\n",
    "# from itertools import product\n",
    "# from tqdm import tqdm\n",
    "# import pickle\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'train'\n",
    "labels = []\n",
    "texts = []\n",
    "with open('train', 'r') as train:\n",
    "    for i, line in enumerate(train):\n",
    "        sample = json.loads(line)\n",
    "        labels.append(sample['label'])\n",
    "        texts.append(sample['text'].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 650000, labels: {1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of documents: {len(texts)}, labels: {set(labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dr',\n",
       " 'goldberg',\n",
       " 'offer',\n",
       " 'everything',\n",
       " 'look',\n",
       " 'general',\n",
       " 'practitioner',\n",
       " 'nice',\n",
       " 'easy',\n",
       " 'talk']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for text in texts:\n",
    "    if 'go' in text:\n",
    "        i += 1\n",
    "        print(text)\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete uninformative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n', 287931),\n",
       " ('go', 278010),\n",
       " ('get', 275094),\n",
       " ('place', 270373),\n",
       " ('good', 249486),\n",
       " ('food', 243176),\n",
       " ('like', 217516),\n",
       " ('would', 209847),\n",
       " ('time', 205797),\n",
       " ('one', 189008),\n",
       " ('service', 187710),\n",
       " ('come', 177887),\n",
       " ('great', 176751),\n",
       " ('back', 166143),\n",
       " ('make', 158980),\n",
       " ('order', 156464),\n",
       " ('really', 147502),\n",
       " ('say', 142458),\n",
       " ('try', 140430),\n",
       " ('take', 135825),\n",
       " ('even', 120517),\n",
       " ('want', 117885),\n",
       " ('give', 117636),\n",
       " ('look', 116667),\n",
       " ('think', 115042),\n",
       " ('could', 114988),\n",
       " ('ni', 114922),\n",
       " ('also', 111680),\n",
       " ('nthe', 108726),\n",
       " ('nice', 107045)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_counter = Counter()\n",
    "for text in texts:\n",
    "    token_to_counter.update(set(text))\n",
    "\n",
    "token_to_counter.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(['n', 'go', 'get', 'even', 'ni', 'also', 'nthe'])\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    texts[i] = [t for t in text if t not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len: 455000, val len: 195000\n"
     ]
    }
   ],
   "source": [
    "train_texts, val_texts, train_target, val_target = train_test_split(texts, labels, test_size=0.3,\n",
    "                                                                    random_state=42, stratify=labels)\n",
    "print(f'Train len: {len(train_texts)}, val len: {len(val_texts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use VowpalWabbit format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vw_file = 'train_vw'\n",
    "val_vw_file = 'val_vw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_vw_file, 'w') as train_vw:\n",
    "    for i, text in enumerate(train_texts):\n",
    "        train_vw.write(f'doc_{i} ' + ' '.join(text) + '\\n')\n",
    "\n",
    "with open(val_vw_file, 'w') as val_vw:\n",
    "    for i, text in enumerate(val_texts):\n",
    "        val_vw.write(f'doc_{i} ' + ' '.join(text) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_0 first sonic burger yesterday expect sonic blast w reese damn though\r\n",
      "doc_1 lot inventory damage disorganize place everything thin coat dirt counter\r\n",
      "doc_2 place awesome today hubby price kid jump hour military discount thank skyzone support troops blast together age fun perfect birthday party venue see couple without kid athletic date outing dress accordingly break sweat suggestion bench seat entrance jump zone least kid zone newborn plus watch kid nowhere sit stand whole time baby food court area cool selection though bring lot business jump enjoy yummy frozen yogurt price lot addon noverall definitely love place often family fun\r\n"
     ]
    }
   ],
   "source": [
    "!head -n3 train_vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_train = artm.BatchVectorizer(data_path=train_vw_file, data_format='vowpal_wabbit',\n",
    "                                batch_size=10000, target_folder='batches/train')\n",
    "bv_val = artm.BatchVectorizer(data_path=val_vw_file, data_format='vowpal_wabbit',\n",
    "                              batch_size=10000, target_folder='batches/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "get_artm = partial(artm.ARTM, dictionary=bv_train.dictionary, class_ids={'@default_class': 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = artm.ARTM(num_topics=10, num_document_passes=3, dictionary=bv_train.dictionary,\n",
    "                  class_ids={'@default_class': 1.0}, cache_theta=True)\n",
    "model.scores.add(artm.PerplexityScore(name='perplexity', dictionary=bv_train.dictionary))\n",
    "model.scores.add(artm.TopTokensScore(name='top-tokens', num_tokens=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter #0, perplexity: 313523.28125\n",
      "Iter #1, perplexity: 2586.05908203125\n",
      "Iter #2, perplexity: 2566.085205078125\n",
      "Iter #3, perplexity: 2519.105224609375\n",
      "Iter #4, perplexity: 2464.97314453125\n",
      "Iter #5, perplexity: 2401.595703125\n",
      "Iter #6, perplexity: 2320.114501953125\n",
      "Iter #7, perplexity: 2236.48388671875\n",
      "Iter #8, perplexity: 2164.56103515625\n",
      "Iter #9, perplexity: 2106.6015625\n",
      "Iter #10, perplexity: 2060.53662109375\n",
      "Iter #11, perplexity: 2023.7037353515625\n",
      "Iter #12, perplexity: 1993.849609375\n",
      "Iter #13, perplexity: 1969.435302734375\n",
      "Iter #14, perplexity: 1949.4158935546875\n",
      "Iter #15, perplexity: 1932.9022216796875\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    model.fit_offline(bv_train, num_collection_passes=1)\n",
    "    print(f'Iter #{i}, perplexity: {model.score_tracker[\"perplexity\"].last_value:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['room', 'stay', 'hotel', 'vegas', 'night', 'strip', 'free', 'like', 'clean', 'nice']\n",
      "['hour', 'happy', 'service', 'look', 'close', 'new', 'amazing', 'year', 'time', 'cut']\n",
      "['tell', 'call', 'take', 'say', 'time', 'show', 'customer', 'ask', 'work', 'never']\n",
      "['place', 'drink', 'bar', 'friend', 'pretty', 'beer', 'people', 'see', 'time', 'night']\n",
      "['chicken', 'burger', 'sauce', 'order', 'eat', 'like', 'fries', 'dish', 'roll', 'sushi']\n",
      "['pizza', 'order', 'cheese', 'small', 'star', 'two', 'give', 'want', 'eat', 'think']\n",
      "['food', 'service', 'restaurant', 'menu', 'table', 'time', 'meal', 'taco', 'nothing', 'seat']\n",
      "['come', 'place', 'order', 'say', 'wait', 'like', 'take', 'minute', 'make', 'time']\n",
      "['little', 'buffet', 'breakfast', 'coffee', 'dessert', 'like', 'cream', 'ice', 'try', 'worth']\n",
      "['find', 'location', 'store', 'like', 'price', 'love', 'look', 'shop', 'need', 'buy']\n"
     ]
    }
   ],
   "source": [
    "top_tokens = model.score_tracker['top-tokens'].last_tokens\n",
    "\n",
    "for topic_name in model.topic_names:\n",
    "    print(top_tokens[topic_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARTM:\n",
    "    def __init__(self, dct, n_topics=10, portion_back=None, tau_back=None, tau_sparse=None, tau_decor=None):\n",
    "        model = artm.ARTM(num_topics=n_topics, num_document_passes=3, dictionary=dct,\n",
    "                          class_ids={'@default_class': 1.0})\n",
    "        model.scores.add(artm.PerplexityScore(name='perplexity', dictionary=dct))\n",
    "        model.scores.add(artm.TopTokensScore(name='top-tokens', num_tokens=10))\n",
    "        model.scores.add(artm.SparsityPhiScore(name='sparsity'))\n",
    "        \n",
    "        if tau_back is not None:\n",
    "            n_back = int(n_topics * portion_back)\n",
    "            model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='smooth', tau=tau_back,\n",
    "                                                                   dictionary=dct,\n",
    "                                                                   topic_names=model.topic_names[:n_back]))\n",
    "        if tau_sparse is not None:\n",
    "            model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='sparse', tau=tau_sparse,\n",
    "                                                                   dictionary=dct,\n",
    "                                                                   topic_names=model.topic_names[n_back:]))\n",
    "        if tau_decor is not None:\n",
    "            model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator', tau=tau_decor))\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "    def fit(self, bv, y=None):\n",
    "        self.model.fit_offline(bv, num_collection_passes=20)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, bv, y=None):\n",
    "        X = self.model.transform(batch_vectorizer=bv).T.to_numpy()\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-195-5c92bf181216>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m artm_svc = Pipeline([\n\u001B[1;32m      2\u001B[0m     \u001B[0;34m(\u001B[0m\u001B[0;34m'artm'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mARTM\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbv_train\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdictionary\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     ('svc', SVC())])\n\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m: name 'SVC' is not defined"
     ]
    }
   ],
   "source": [
    "artm_svc = Pipeline([\n",
    "    ('artm', ARTM(bv_train.dictionary)),\n",
    "    ('svc', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(bv, n_topics, portion_back=None, tau_back=None, tau_sparse=None, tau_decor=None):\n",
    "    model = artm.ARTM(num_topics=n_topics, num_document_passes=3, dictionary=bv.dictionary,\n",
    "                      class_ids={'@default_class': 1.0})\n",
    "    model.scores.add(artm.PerplexityScore(name='perplexity', dictionary=bv.dictionary))\n",
    "    model.scores.add(artm.TopTokensScore(name='top-tokens', num_tokens=10))\n",
    "    model.scores.add(artm.SparsityPhiScore(name='sparsity'))\n",
    "    \n",
    "    if portion_back is not None:\n",
    "        n_back = int(n_topics * portion_back)\n",
    "        model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='smooth', tau=tau_back,\n",
    "                                                               dictionary=bv.dictionary,\n",
    "                                                               topic_names=model.topic_names[:n_back]))\n",
    "    if tau_sparse is not None:\n",
    "        model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='sparse', tau=tau_sparse,\n",
    "                                                               dictionary=bv.dictionary,\n",
    "                                                               topic_names=model.topic_names[n_back:]))\n",
    "        model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator', tau=tau_decor))\n",
    "\n",
    "    model.fit_offline(bv, num_collection_passes=20)\n",
    "    parameters = {'n_topics': n_topics, 'portion_back': portion_back, 'tau_back': tau_back,\n",
    "                  'tau_sparse': tau_sparse, 'tau_decor': tau_decor}\n",
    "    return model, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(artm_model, bv_train, bv_val, cls, train_target, val_target):\n",
    "    train_X = artm_model.transform(batch_vectorizer=bv_train).T.to_numpy()\n",
    "    val_X = artm_model.transform(batch_vectorizer=bv_val).T.to_numpy()\n",
    "    cls.fit(X=train_X, y=train_target)\n",
    "    return f1_score(y_true=val_target, y_pred=cls.predict(X=val_X), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_topics = [10, 20]\n",
    "\n",
    "taus_back = [1e2, 1e3]\n",
    "portions_back = [0.1, 0.2, 0.3, 0.4]\n",
    "taus_sparse = [1e2, 1e3]\n",
    "taus_decor = [1e5, 1e6]\n",
    "\n",
    "classifiers = ['LogReg', 'SVM']\n",
    "name_to_cls = {'LogReg': LogisticRegression(), 'SVM': LinearSVC()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [16:43, 250.83s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "grid = product(N_topics, classifiers)\n",
    "for n_topics, cls_name in tqdm(grid):\n",
    "    model, parameters = get_model(bv_train, n_topics)\n",
    "    parameters['cls'] = cls_name\n",
    "    f1 = classify(model, bv_train, bv_val, name_to_cls[cls_name], train_target, val_target)\n",
    "    top_tokens = model.score_tracker['top-tokens'].last_tokens\n",
    "    result = {'parameters': parameters,\n",
    "              'perplexity': model.score_tracker[\"perplexity\"].value,\n",
    "              'sparsity': model.score_tracker[\"sparsity\"].value,\n",
    "              'top-tokens': [top_tokens[topic_name] for topic_name in model.topic_names],\n",
    "              'f1': f1}\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = 'results'\n",
    "with open(f'{results_dir}/result_noreg.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_topics': 10,\n",
       " 'portion_back': None,\n",
       " 'tau_back': None,\n",
       " 'tau_sparse': None,\n",
       " 'tau_decor': None,\n",
       " 'cls': 'LogReg'}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]['parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Perplexity')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 20), results[0]['perplexity'][1:], label=\"10 topics\")\n",
    "plt.plot(range(1, 20), results[2]['perplexity'][1:], label=\"20 topics\")\n",
    "plt.xlabel(\"Iteration number\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Sparsity')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlu0lEQVR4nO3dd3xV9f3H8deHsGULshGUIaAsA6LVFqs4W6nV1s1w4Gzd1tr+rNqh1tbWWjuoCoooiKPSFourWq2tJGGHDTLCCCBhryT38/vjnuA1JiRATs69ue/n45FHzvjeez85ufe+7z3j+zV3R0RE0letqAsQEZFoKQhERNKcgkBEJM0pCERE0pyCQEQkzdWOuoCD1bJlS+/cuXPUZYiIpJScnJxN7t6qrHUpFwSdO3cmOzs76jJERFKKma0sb512DYmIpDkFgYhImlMQiIikOQWBiEiaUxCIiKQ5BYGISJpTEIiIpDkFgYhIkttXFOMXUxewdsvuUO5fQSAiksQ279zHlc98wph/L+e9hRtCeYyUu7JYRCRdLM7fzjXPZZG/bS9PXNqPYf3ah/I4CgIRkST03sJ8vv/SLBrUzWDS6MH079Q8tMdSEIiIJBF35y8fLufhNxfSu10T/jI8k7ZNG4T6mAoCEZEksbeomB+/Po/JOXmcd0IbfvWdvjSsG/7btIJARCQJbNqxlxtfyCFrRQHfP6Mbt53RjVq1rFoeW0EgIhKxBeu2ce1z2WzasZcnL+vPN/u2q9bHVxCIiETordz13DZpFo3r12byDSfTp0Ozaq9BQSAiEgF3548fLOOxaYvo074pY4Zn0rpJ/UhqURCIiFSzPYXF3PfaXF6buYZv9m3HYxf3oX6djMjqURCIiFSjDdv3cP34HGau2sIdQ7vzva93xax6DgqXR0EgIlJNctdu5brnsinYVcgfrxjAuSe0jbokQEEgIlIt/jlvPbdPmkWzhnWYfMPJHN++adQl7acgEBEJ2dj/fMqDf5tPv47NGHPViRwV0UHh8igIRERC4u48/vZinnxvKWf1as3vLusf6UHh8igIRERCUBxz/u+Nebz4ySouyezIzy88ntoZydnzv4JARKSK7S0q5raJs3hz3npuGnIsd5/dI/Izgw5EQSAiUoW27ynk+vE5fLzsM358fk+uPe2YqEuqkIJARKSKbNqxl5Fjp7Nw3XZ+c0lfLuzfIeqSKiXUHVZmdo6ZLTKzpWZ27wHaXWRmbmaZYdYjIhKW1Zt38Z0//ZelG3bwl+GZKRMCEOI3AjPLAJ4ChgJ5QJaZTXH3+aXaNQZuBT4JqxYRkTAtXL+N4c9MZ29RjAnXDubEo8MbTSwMYX4jGAQsdffl7r4PmAgMK6PdT4FHgT0h1iIiEorsFZv57p/+ixlMvuHklAsBCDcI2gOrE+bzgmX7mdkAoKO7/yPEOkREQvHugnyuePoTWjaqx6s3nkL31o2jLumQRHaw2MxqAY8DIyvRdjQwGqBTp07hFiYiUgmv5uRxz6tz6N2uCWNHDuTIRvWiLumQhfmNYA3QMWG+Q7CsRGPgeOB9M1sBDAamlHXA2N3HuHumu2e2atUqxJJFRCr29IfLuXPybAYf04IXrxuc0iEA4X4jyAK6mVkX4gFwKXB5yUp33wq0LJk3s/eBu9w9O8SaREQOmbvz6D8X8acPlnH+CW15/JK+1KudfF1GHKzQgsDdi8zsFmAakAE86+65ZvYQkO3uU8J6bBGRqlZUHOO+1+fycnYeVw7uxIMXHE9GNQ0uH7ZQjxG4+1Rgaqll95fTdkiYtYiIHKq9RcXc8uJM3p6fz61ndOO2M7sldZcRB0tXFouIHMDeomJuGJ/DvxZt5MELejPilM5Rl1TlFAQiIuVIDIGHv30Clw2qmWctJmefqCIiEdtbVMyNL8yo8SEACgIRkS8pCYH3Fm7gFxfW7BAABYGIyBeUDoHLT6rZIQAKAhGR/fYWFXNTEAI/v/D4tAgBUBCIiACfh8C7QQhccdLRUZdUbRQEIpL29hYVc/OEeAj87FvpFQKgIBCRNFcSAu8siIfAlYPTKwRAQSAiaWxfUWx/CPw0TUMAFAQikqb2FcW4aULO/hC4Kk1DABQEIpKGvhACw3qndQiAgkBE0kw8BGZ8HgInd466pMgpCEQkbXweAvk8pBDYT0EgImlhX1GMm1/8PASGKwT2UxCISI1XWBwPgbfnKwTKoiAQkRotFnPumjybt+fn8+AFCoGyKAhEpMZydx78Wy5vzFrL3Wf3qJGDylQFBYGI1Fi/e3cpz/13Jded1oWbhhwbdTlJS0EgIjXScx+v4DfvLObiEztw33k9a9QYw1VNQSAiNc4bs9bwkym5DO3Vmke+fYJCoAIKAhGpUf61cAN3vjybk7q04MnL+lM7Q29zFdEWEpEaI3vFZm6ckMNxbRvz9IhM6tfJiLqklKAgEJEaYcG6bVw9Lot2TRswbtQgGtevE3VJKUNBICIpb+VnOxn+7HQa1q3N89cMomWjelGXlFIUBCKS0jZs28NVz0ynsDjG+GsG0aF5w6hLSjkKAhFJWVt3FTL82els2rGXcaMG0a1146hLSkkKAhFJSbv3FXPNc1ks27iDMVdl0q9js6hLSlkKAhFJOYXFMW6ckMOMVQU8cWl/Tu3WMuqSUlrtqAsQETkYJZ3Ivb9oIw9/+wTOO6Ft1CWlPH0jEJGUkdiJ3D3n9OCyQZ2iLqlGUBCISMp44t0l+zuRu/Fr6kSuqigIRCQljPvPp/z2nSV8R53IVTkFgYgkvb/PWcsDf5vPWb1a87A6katyCgIRSWqfLP+MOybNZmDn5vxOnciFItQtambnmNkiM1tqZveWsf4GM5trZrPM7CMz6xVmPSKSWpbkb+e657Pp2KIBfxmuTuTCEloQmFkG8BRwLtALuKyMN/oX3f0Ed+8H/BJ4PKx6RCS15G/bw8ixWdSrk8G4UYNo1rBu1CXVWGF+IxgELHX35e6+D5gIDEts4O7bEmaPADzEekQkRezYW8SosVkU7NrH2JED6dhC/QeFKcwLytoDqxPm84CTSjcys5uBO4C6wNfLuiMzGw2MBujUSecNi9RkhcUxbpowg0X523lmRCbHt28adUk1XuRHXdz9KXc/FvgB8ONy2oxx90x3z2zVqlX1Figi1cbdue+1ufx78UZ+ceHxDOlxVNQlpYUwg2AN0DFhvkOwrDwTgW+FWI+IJLnfvrOEyTl53HpGNy4ZqG//1SXMIMgCuplZFzOrC1wKTElsYGbdEmbPB5aEWI+IJLFJWat44t34BWO3ndmt4htIlQntGIG7F5nZLcA0IAN41t1zzewhINvdpwC3mNmZQCFQAIwIqx4RSV7vL9rAfa/P46vdW/ELXTBW7ULtfdTdpwJTSy27P2H61jAfX0SS37w1W7lpwgx6tG7MH64YQB1dMFbttMVFJDKrN+9i5Ngsmjesy7hRA2lUTz3jR0FbXUQisWXXPkaMnc6+omImjj6Jo5rUj7qktKUgEJFqt6ewmOuezyZv827GXzOIrkdprOEoKQhEpFrFYs4dL88ia0UBv7+8Pycdc2TUJaU9HSMQkWr186kLmDp3PT8+vyff6NMu6nIEBYGIVKNnPvqUZz76lJGndOaaU7tEXY4EFAQiUi2mzl3Hz/4xn3N6t+H/vtFL1wokEQWBiIQuZ+Vmbps0iwGdmvPbS/uRUUshkEwUBCISqhWbdnLtc9m0a1pfg8skqUoFgZmdEHYhIlLzFOzcx9XjsgAYO2oQLY7Q4DLJqLLfCP5gZtPN7CYzU+fgIlKhvUXFXP9CDnkFuxkzPJMuLY+IuiQpR6WCwN1PA64g3q10jpm9aGZDQ61MRFKWu3Pvq3OZ/ulmHvtOHwZ2bhF1SXIAlT5G4O5LiA8c8wPga8DvzGyhmX07rOJEJDX99p0lvD5zDXed1Z1h/dpHXY5UoLLHCPqY2W+ABcSHk/ymu/cMpn8TYn0ikmJezcnjiXeXcPGJHbj59K5RlyOVUNkuJp4Engbuc/fdJQvdfa2ZlTm8pIikn/8u+4x7X5vDKcceyS8u1LgCqaKyu4Zed/fxiSFgZrcCuPv4UCoTkZSydMMOrh+fzdFHHsEfrzyRurV1dnqqqOx/angZy0ZWYR0iksI+27GXq8dlUSejFmNHDqRpgzpRlyQH4YC7hszsMuByoIuZJY433BjYHGZhIpIaSrqUzt+2h4mjB9OxRcOoS5KDVNExgo+BdUBL4NcJy7cDc8IqSkRSQyzm3Dl5NjNWbeGPVwygf6fmUZckh+CAQeDuK4GVwMnVU46IpJJfvbWIf8xZxw/PPY5zT2gbdTlyiCraNfSRu59qZtsBT1wFuLs3CbU6EUlaE6ev4g/vL+Pykzox+qvHRF2OHIaKvhGcGvzWOHIist+HSzbyo7/O46vdW/HQBb11mmiKq+wFZceaWb1geoiZfd/MmoVamYgkpcX527nphRl0O6oRT13en9oZOk001VX2P/gqUGxmXYExxPscejG0qkQkKW3YvodRY7NoUDeDZ0cOpHF9nSZaE1Q2CGLuXgRcCDzp7ncDOjIkkkZ27yvm2uey2bxzH8+MGEi7Zg2iLkmqSGWDoDC4pmAE8PdgmT4KiKSJ4phz26SZzF2zld9d1p8TOqg3+pqkskEwivgppD9390/NrAugriVE0oC789O/z2dabj7/d34vhvZqHXVJUsUq7HTOzDKAH7n7FSXL3P1T4NEwCxOR5DDm38sZ9/EKrj21C1ef2iXqciQEFX4jcPdi4Ggz0xhzImnmrzPX8PCbC/lGn7bcd17PqMuRkFS2G+rlwH+C/oZ2lix098dDqUpEIvfRkk3c/cpsBh/Tgl9/ty+1aulagZqqskGwLPipRbzDORGpwXLXbuWGF3I4tlUj/nxVJvVqZ0RdkoSoUkHg7g+GXYiIJIfVm3cxcmwWTerXZtyoQepSOg1UKgjMrBVwD9AbqF+y3N2/HlJdIhKBgp37GDF2OnsLi5lw4ym0aVq/4htJyqvs6aMTgIVAF+BBYAWQFVJNIhKBPYXFXPt8NnkFu3l6xEC6t9Ze4HRR2SA40t2fAQrd/QN3v5r4wPUiUgMUx5zvvzSTGasK+O0l/RjUpUXUJUk1qvSVxcHvdWZ2vpn1Byp8ppjZOWa2yMyWmtm9Zay/w8zmm9kcM3vXzI4+iNpFpAq4Ow9MyeWt+fn85Bu9OE/jCqSdygbBz8ysKXAncBfwNHD7gW4QXIj2FHAu0Au4zMx6lWo2E8h09z7AK8AvD6J2EakCf3h/GeP/t5Lrv3YMI7+iC8bSUWXPGirpX2grcHol73sQsNTdlwOY2URgGDA/4X7/ldD+f8CVlbxvEakCr+Tk8di0RXyrXzt+cPZxUZcjEanseATHmNnfzGyTmW0wszfMrKIhidoDqxPm84Jl5bkGeLOcxx9tZtlmlr1x48bKlCwiFfhg8UbufXUOX+l6JL+8WBeMpbPK7hp6EXgZaAO0AyYDL1VVEWZ2JZAJPFbWencf4+6Z7p7ZqlWrqnpYkbQ1N28rN76QQ7fWjfnTlSdSt7YGl0lnlf3vN3T38e5eFPy8QML1BOVYQ3wAmxIdgmVfYGZnAj8CLnD3vZWsR0QO0arPdjFq3HSaN6zLuFEaXEYqHwRvmtm9ZtbZzI42s3uAqWbWwszKO3soC+hmZl2CDusuBaYkNgjOPvoz8RDYcKh/hIhUzubggrGimPPc1YNo3UQXjEnl+xr6bvB7dPC7ZGfipYADXzpe4O5FZnYLMA3IAJ5191wzewjIdvcpxHcFNQImB4Nfr3L3Cw7pLxGRA9q9r5irx2WxdstuJlx7El2PahR1SZIkDhgEZjYQWO3uXYL5EcBFxK8sfsDdNx/o9u4+FZhaatn9CdNnHlrZInIwiopjfO+lGczJ28IfrzyRzM66YEw+V9GuoT8D+wDM7KvAw8BzxE8jHRNuaSJSFYqKY9w2aRbvLNjAgxf05uzebaIuSZJMRbuGMhI+9V8CjHH3V4FXzWxWqJWJyGErCYG/z1nHD889jqtO7hx1SZKEKvpGkGFmJWFxBvBewrrKHl8QkQgUFce4/eXZ+0Pg+q8dG3VJkqQqejN/CfjAzDYBu4EPAcysK/HdQyKShIqKY9zx8mz+Nnst9yoEpAIHDAJ3/7mZvQu0Bd5ydw9W1QK+F3ZxInLwiopj3Dl5NlNmr+UH5xzHDQoBqUCFu3fc/X9lLFscTjkicjiKY86dk2fzxqy13HNOD24cohCQium6cpEaojjm3PHyLN6YtZa7z+7BTUO6Rl2SpAgFgUgNUBxz7kwIgZtPVwhI5SkIRFJcccy5a/Js/qoQkEOkIBBJYcUx5+7Js3l95hruOqu7QkAOiYJAJEUVx5y7X5nNazPXcOfQ7tzy9W5RlyQpSkEgkoKKY849r8zhtRlruGNod753hkJADp2CQCTFlITAqzPyuGNod76vEJDDpCAQSSHFMecHr8ZD4PYzFQJSNRQEIikiFnPufXUOr+TkcduZ3bj1TIWAVA0FgUgKKI459742h8k5edx6RjduO7N71CVJDaIeREWS3LY9hdw2cRbvLdzA98/oxu1DFQJStRQEIkls+cYdXPd8Nis/28VPv3U8Vw0+OuqSpAZSEIgkqQ8Wb+R7L86gdkYtXrj2JAYfc2TUJUkNpSAQSTLuzjMffcovpi6ge+vG/GV4Jh1bNIy6LKnBFAQiSWRPYTH3vT6X12as4bwT2vCr7/SlYV29TCVceoaJJIn8bXsYPT6H2au3xK8W/npXzCzqsiQNKAhEksDMVQVcPz6HnXuL+PNVJ3J27zZRlyRpREEgErFXc/L44etzad2kHuOv+Qo92jSOuiRJMwoCkYgUFcd45M2FPP3Rp5xy7JE8dfkAmh9RN+qyJA0pCEQisHVXIbe8NIMPl2xi5Cmd+dH5PamToQv9JRoKApFqtnTDdq57Poe8gl08etEJXDKwU9QlSZpTEIhUo/cW5nPrS7OoV6cWL103mMzOLaIuSURBIFIdYjHnT/9exmPTFtG7XRPGXJVJu2YNoi5LBFAQiITu42WbeHjqQuau2co3+7bjlxf1oUHdjKjLEtlPQSASksX523nkzYW8t3AD7ZrW5/Hv9uXC/u11kZgkHQWBSBVbv3UPv3l7MZNzVnNEvdr88NzjGHFKZ+rX0bcASU4KApEqsn1PIX/+YDlPf7Sc4pgz6itduOX0rro2QJKegkDkMBUWx3hp+iqeeGcJn+3cxwV923H32T3UY6ikDAWByCFyd/45bz2/nLaITzft5KQuLXj2vJ707dgs6tJEDkqolzKa2TlmtsjMlprZvWWs/6qZzTCzIjO7OMxaRKpS9orNXPTHj7lxwgxq1zKeHZnJxNGDFQKSkkL7RmBmGcBTwFAgD8gysynuPj+h2SpgJHBXWHWIVKVlG3fwy38uZFpuPkc1rsejF53ARQM6UFvdQ0gKC3PX0CBgqbsvBzCzicAwYH8QuPuKYF0sxDpEDou7k7t2GxOzVvHS9NXUr12LO4d255rTumjQGKkRwnwWtwdWJ8znAScdyh2Z2WhgNECnTuqXRcJXHHOyV2xmWm4+b81fT17BbjJqGZcP6sStZ3ajZaN6UZcoUmVS4uOMu48BxgBkZmZ6xOVIDbWnsJj/LN3EW7n5vLMgn8927qNuRi1O7daS7329K2f0bK0AkBopzCBYA3RMmO8QLBNJGtv2FPKvhRt4Kzef9xdtYOe+YhrVq83pxx3F2b1bM6THUTSqlxKfl0QOWZjP8Cygm5l1IR4AlwKXh/h4IpWycfte3p6fz7Tc9Xy8bBOFxU7LRvW4oF97zu7dmpOPPZJ6tXUVsKSP0ILA3YvM7BZgGpABPOvuuWb2EJDt7lPMbCDwOtAc+KaZPejuvcOqSdLTzr1FLFi3jRmrCngrN5+cVQW4w9FHNmTUV7pwVq/W9O/UnIxa6gNI0pO5p9Yu98zMTM/Ozo66DElSm3bsJXftNnLXbmX+2m3MX7uNTz/bScnTvFfbJpzduw1nH9+aHq0bqwM4SRtmluPumWWt085PSUnuzurNu8ldu5XctduYvy7+5p+/be/+Nh2aN6B3uyYM69ee3u2acHz7prRpWj/CqkWSk4JAkl4s5izftJPZq7cwr+ST/rptbN9TBEBGLaNrq0Z85diW9GrXhF7tmtC7bVOaNqwTceUiqUFBIEln255CZq/ewoyVW5i5uoCZq7awdXchAPXr1KJn2yYM69eO3u2a0qttE3q0aawunkUOg4JAIhWLOcs27mDmqi3MWFXAjFUFLNmwA3cwg+5HNebc49swoFNz+ndqxjGtGumgrkgVUxBItdq6u5BZq7cwY2UBM1dvYdaqArYFu3iaNqhD/07N+Eafdgzo1Jw+HZvSpL5274iETUEg1eLNuev47TtLWJS/HYBaBt1bN+b8Pu0Y0KkZA45uTpcjj6CWPu2LVDsFgYRqx94iHpySy+ScPHq2bcKdQ7sz4Ojm9O3YTFfsiiQJvRIlNDkrC7h90izyCnZxy+ldufXMbtRRd80iSUdBIFWuqDjGk+8t5ff/WkqbJvWZdP3JDOzcIuqyRKQcCgKpUis/28ltk2Yxc9UWvt2/PQ8M660DviJJTkEgVcLdmZyTx4NTcsmoZTx5WX++2bdd1GWJSCUoCOSwFezcx32vz+XNeesZfEwLHv9uP9o1axB1WSJSSQoCOSwfLdnEnZNnsXnnPn547nFcd9oxOgVUJMUoCOSQ7Cks5rFpi3jmo0/pelQjnhkxkOPbN426LBE5BAoCOWiL1m/n1okzWbh+O8NPPpofntuTBnXV149IqlIQSKXFYs64j1fwyD8X0qR+bcaOHMjpxx0VdVkicpgUBFIpm3fu49aJM/lwySbO7HkUj1zURwO5i9QQCgKp0J7CYq59Lot5a7fx8wuP5/JBnTSyl0gNoiCQA4rFnDtfns3M1Vv4w+UDOPeEtlGXJCJVTB2/yAE9Om0h/5i7jvvO7akQEKmhFARSrgmfrOTPHyznysGduPa0LlGXIyIhURBImd5ftIH738jl9B6teOCbvXVMQKQGUxDIl8xfu42bJ8ygR+vG/P7yAdRW19EiNZpe4fIF67bu5upxWTRpUIdnRw7kCA0eI1Lj6VUu++3YW8TV47LZsbeIyTecTJum9aMuSUSqgYJAgPhgMjdPmMHi/O08O3IgPds2ibokEakm2jUkuDv3T8nlg8Ub+dm3judr3VtFXZKIVCMFgTDm38t58ZNV3DjkWC4b1CnqckSkmikI0tw/5qzj4TcX8o0+bbn7rB5RlyMiEVAQpLGclZu5/eVZnHh0c371nb4aUEYkTSkI0tTKz3Zy3fM5tGtan78Mz6R+HY0nIJKuFARpqGDnPkaNzcLdGTtqEC2OqBt1SSISIZ0+mmb2FhVz/fgc8gp2M+G6k+jS8oioSxKRiCkI0kgs5tw9eQ7TV2zmd5f1Z2DnFlGXJCJJQLuG0sjjby9myuy13H12Dy7o2y7qckQkSYT6jcDMzgGeADKAp939kVLr6wHPAycCnwGXuPuKMGuqyYqKY6zbuoe8gt2s2bKbvIJd8emC3eRt2cXqzbu5dGBHbhpybNSlikgSCS0IzCwDeAoYCuQBWWY2xd3nJzS7Bihw965mdinwKHBJWDWlun1FMdZtDd7YC4I3+i2797/Zr9+2h+KY729vBkc1rkeH5g0Z0Kk5lw86mmtP66IupUXkC8L8RjAIWOruywHMbCIwDEgMgmHAA8H0K8Dvzczc3aliL2etZsyHy7+0vKyHKvfB/fNfJbcraev71/nn06XuyN2JebxNzOPz7hDzcuZLtSuKffEOaxm0aVKfDs0bMqhLCzo0b0CH5g1o36whHZo3oG2z+tSrrdNCReTAwgyC9sDqhPk84KTy2rh7kZltBY4ENiU2MrPRwGiATp0OrQuE5kfUpUfrxmWvLOMDcnmfmUs+TRvxT9yJbRPXsX9dsCyYr2VQywwzwyxhPrh9rdLLE+brZNSiXbP4m32HZg1p07Q+dWvrMI+IHJ6UOGvI3ccAYwAyMzMP6dvC0F6tGdqrdZXWJSJSE4T5cXIN0DFhvkOwrMw2ZlYbaEr8oLGIiFSTMIMgC+hmZl3MrC5wKTClVJspwIhg+mLgvTCOD4iISPlC2zUU7PO/BZhG/PTRZ90918weArLdfQrwDDDezJYCm4mHhYiIVKNQjxG4+1Rgaqll9ydM7wG+E2YNIiJyYDrlREQkzSkIRETSnIJARCTNKQhERNKcpdrZmma2EVh5iDdvSamrlpOM6js8qu/wJXuNqu/QHe3urcpakXJBcDjMLNvdM6Ouozyq7/CovsOX7DWqvnBo15CISJpTEIiIpLl0C4IxURdQAdV3eFTf4Uv2GlVfCNLqGIGIiHxZun0jEBGRUhQEIiJprkYGgZmdY2aLzGypmd1bxvp6ZjYpWP+JmXWuxto6mtm/zGy+meWa2a1ltBliZlvNbFbwc39Z9xVijSvMbG7w2NllrDcz+12w/eaY2YBqrK1HwnaZZWbbzOy2Um2qffuZ2bNmtsHM5iUsa2Fmb5vZkuB383JuOyJos8TMRpTVJoTaHjOzhcH/73Uza1bObQ/4XAi5xgfMbE3C//G8cm57wNd7iPVNSqhthZnNKue21bIND0t8PNya80O8y+tlwDFAXWA20KtUm5uAPwXTlwKTqrG+tsCAYLoxsLiM+oYAf49wG64AWh5g/XnAm8QH5BwMfBLh/3o98QtlIt1+wFeBAcC8hGW/BO4Npu8FHi3jdi2A5cHv5sF082qo7SygdjD9aFm1Vea5EHKNDwB3VeI5cMDXe1j1lVr/a+D+KLfh4fzUxG8Eg4Cl7r7c3fcBE4FhpdoMA54Lpl8BzrCSAYdD5u7r3H1GML0dWEB87OZUMgx43uP+BzQzs7YR1HEGsMzdD/VK8yrj7v8mPqZGosTn2XPAt8q46dnA2+6+2d0LgLeBc8Kuzd3fcveiYPZ/xEcQjEw5268yKvN6P2wHqi947/gu8FJVP251qYlB0B5YnTCfx5ffaPe3CV4MW4Ejq6W6BMEuqf7AJ2WsPtnMZpvZm2bWu3orw4G3zCzHzEaXsb4y27g6XEr5L74ot1+J1u6+LpheD5Q1aHYybMuriX/DK0tFz4Ww3RLsvnq2nF1rybD9TgPy3X1JOeuj3oYVqolBkBLMrBHwKnCbu28rtXoG8d0dfYEngb9Wc3mnuvsA4FzgZjP7ajU/foUsPvzpBcDkMlZHvf2+xOP7CJLuXG0z+xFQBEwop0mUz4U/AscC/YB1xHe/JKPLOPC3gaR/PdXEIFgDdEyY7xAsK7ONmdUGmgKfVUt18cesQzwEJrj7a6XXu/s2d98RTE8F6phZy+qqz93XBL83AK8T//qdqDLbOGznAjPcPb/0iqi3X4L8kl1mwe8NZbSJbFua2UjgG8AVQVB9SSWeC6Fx93x3L3b3GPCXch470udi8P7xbWBSeW2i3IaVVRODIAvoZmZdgk+NlwJTSrWZApScnXEx8F55L4SqFuxPfAZY4O6Pl9OmTckxCzMbRPz/VC1BZWZHmFnjkmniBxXnlWo2BRgenD00GNiasAukupT7KSzK7VdK4vNsBPBGGW2mAWeZWfNg18dZwbJQmdk5wD3ABe6+q5w2lXkuhFlj4nGnC8t57Mq83sN0JrDQ3fPKWhn1Nqy0qI9Wh/FD/KyWxcTPJvhRsOwh4k96gPrEdyksBaYDx1RjbacS30UwB5gV/JwH3ADcELS5BcglfgbE/4BTqrG+Y4LHnR3UULL9Eusz4Klg+84FMqv5/3sE8Tf2pgnLIt1+xENpHVBIfD/1NcSPO70LLAHeAVoEbTOBpxNue3XwXFwKjKqm2pYS37de8hwsOYuuHTD1QM+Fatx+44Pn1xzib+5tS9cYzH/p9V4d9QXLx5U87xLaRrIND+dHXUyIiKS5mrhrSEREDoKCQEQkzSkIRETSnIJARCTNKQhERNKcgkBSgpntCH53NrPLq/i+7ys1/3FV3n9VM7ORZvb7qOuQmkNBIKmmM3BQQRBc/XkgXwgCdz/lIGtKKWaWEXUNklwUBJJqHgFOC/p2v93MMoK+9bOCzsmuh/1jEnxoZlOA+cGyvwYdf+WWdP5lZo8ADYL7mxAsK/n2YcF9zwv6k78k4b7fN7NXLN6n/4Syeq8N2jxqZtPNbLGZnRYs/8InejP7u5kNKXns4DFzzewdMxsU3M9yM7sg4e47BsuXmNlPEu7ryuDxZpnZn0ve9IP7/bWZzQZOrqL/hdQUUV/Rph/9VOYH2BH8HkLCWAPAaODHwXQ9IBvoErTbCXRJaFtyZW8D4pf5H5l432U81kXEu4XOIN5z6Cri40kMId5jbQfiH6b+S7xjsdI1vw/8Opg+D3gnmB4J/D6h3d+BIcG0A+cG068DbwF1gL7ArITbryN+5XLJ35IJ9AT+BtQJ2v0BGJ5wv9+N+v+on+T8qegrs0iyOwvoY2YXB/NNgW7APmC6u3+a0Pb7ZnZhMN0xaHegPohOBV5y92LiHch9AAwEtgX3nQdg8ZGpOgMflXEfJZ0K5gRtKrIP+GcwPRfY6+6FZja31O3fdvfPgsd/Lai1CDgRyAq+oDTg847uiol3dCjyJQoCSXUGfM/dv9BRW7CrZWep+TOBk919l5m9T7zPqUO1N2G6mPJfS3vLaFPEF3fLJtZR6O4l/b7ESm7v7rFSxzpK9w3jxLfFc+7+wzLq2BMEmsiX6BiBpJrtxIf4LDENuDHo2hsz6x708lhaU6AgCIHjiA+xWaKw5PalfAhcEhyHaEV8uMLpVfA3rAD6mVktM+vIoXVLPNTiYyI3ID7y2X+Id3B3sZkdBfvHTD66CuqVGk7fCCTVzAGKg4Oe44AniO8ymREcsN1I2UNC/hO4wcwWAIuI90paYgwwx8xmuPsVCctfJ35gdTbxT9z3uPv6IEgOx3+AT4kfxF5AfCCdgzWd+K6eDsAL7p4NYGY/Jj4aVi3iPWXeDEQ+lKckN/U+KiKS5rRrSEQkzSkIRETSnIJARCTNKQhERNKcgkBEJM0pCERE0pyCQEQkzf0/qDBD5uFbXjQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(results[0]['sparsity'], label=\"10 topics\")\n",
    "plt.plot(results[2]['sparsity'], label=\"20 topics\")\n",
    "plt.xlabel(\"Iteration number\")\n",
    "plt.ylabel(\"Sparsity\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for LogReg, 10 topics: 0.1992\n",
      "F1 score for SVM, 10 topics: 0.1993\n",
      "F1 score for LogReg, 20 topics: 0.1988\n",
      "F1 score for SVM, 20 topics: 0.1988\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    print(f\"F1 score for {res['parameters']['cls']}, {res['parameters']['n_topics']} topics: {res['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding background topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [56:43, 283.63s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-190-a9b81e62abc2>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mgrid\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mproduct\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mN_topics\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclassifiers\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;36m1e3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mportions_back\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mn_topics\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcls_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtau_back\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mportion_back\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgrid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparameters\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbv_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_topics\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mportion_back\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mportion_back\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtau_back\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtau_back\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m     \u001B[0mparameters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'cls'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcls_name\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mf1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclassify\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbv_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbv_val\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname_to_cls\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcls_name\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_target\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_target\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-136-60dda5a826eb>\u001B[0m in \u001B[0;36mget_model\u001B[0;34m(bv, n_topics, portion_back, tau_back, tau_sparse, tau_decor)\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mregularizers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0martm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDecorrelatorPhiRegularizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'decorrelator'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtau\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtau_decor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit_offline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_collection_passes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m     parameters = {'n_topics': n_topics, 'portion_back': portion_back, 'tau_back': tau_back,\n\u001B[1;32m     21\u001B[0m                   'tau_sparse': tau_sparse, 'tau_decor': tau_decor}\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/artm/artm_model.py\u001B[0m in \u001B[0;36mfit_offline\u001B[0;34m(self, batch_vectorizer, num_collection_passes, reset_nwt)\u001B[0m\n\u001B[1;32m    555\u001B[0m                     self._pool.apply_async(func=self.master.fit_offline,\n\u001B[1;32m    556\u001B[0m                                            args=(batch_vectorizer.batches_ids,\n\u001B[0;32m--> 557\u001B[0;31m                                                  batch_vectorizer.weights, 1, None, reset_nwt)),\n\u001B[0m\u001B[1;32m    558\u001B[0m                     batch_vectorizer.num_batches)\n\u001B[1;32m    559\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/artm/artm_model.py\u001B[0m in \u001B[0;36mapply_async\u001B[0;34m(self, func, args)\u001B[0m\n\u001B[1;32m     97\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 99\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pool\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pool\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    100\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    101\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__deepcopy__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmemo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/artm/master_component.py\u001B[0m in \u001B[0;36mfit_offline\u001B[0;34m(self, batch_filenames, batch_weights, num_collection_passes, batches_folder, reset_nwt)\u001B[0m\n\u001B[1;32m    839\u001B[0m             \u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_folder\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatches_folder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    840\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 841\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mArtmFitOfflineMasterModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmaster_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    842\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    843\u001B[0m     def fit_online(self, batch_filenames=None, batch_weights=None, update_after=None,\n",
      "\u001B[0;32m~/.local/lib/python3.7/site-packages/artm/wrapper/api.py\u001B[0m in \u001B[0;36martm_api_call\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    158\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mspec\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult_type\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m                 \u001B[0mfunc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrestype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mspec\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult_type\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 160\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mc_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    161\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    162\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "grid = product(N_topics, classifiers, [1e3], portions_back)\n",
    "for n_topics, cls_name, tau_back, portion_back in tqdm(grid):\n",
    "    model, parameters = get_model(bv_train, n_topics, portion_back=portion_back, tau_back=tau_back)\n",
    "    parameters['cls'] = cls_name\n",
    "    f1 = classify(model, bv_train, bv_val, name_to_cls[cls_name], train_target, val_target)\n",
    "    top_tokens = model.score_tracker['top-tokens'].last_tokens\n",
    "    result = {'parameters': parameters,\n",
    "              'perplexity': model.score_tracker[\"perplexity\"].value,\n",
    "              'sparsity': model.score_tracker[\"sparsity\"].value,\n",
    "              'top-tokens': [top_tokens[topic_name] for topic_name in model.topic_names],\n",
    "              'f1': f1}\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{results_dir}/result_back.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls_name in classifiers:\n",
    "    for n_topics in N_topics:\n",
    "        scores = [res['f1'] for res in results if res['parameters']['cls'] == cls_name\\\n",
    "                  and res['parameters']['n_topics'] == n_topics]\n",
    "        plt.plot(portions_back, scores, label=f\"{cls_name}, {n_topics} topics\")\n",
    "        plt.xlabel(\"Background themes portion\")\n",
    "        plt.ylabel(\"F1\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics_best = 10\n",
    "cls_name_best = 'LogReg'\n",
    "tau_back_best = 1e3\n",
    "\n",
    "results = []\n",
    "grid = product(portions_back, taus_decor)\n",
    "for portion_back, tau_decor in tqdm(grid):\n",
    "    model, parameters = get_model(bv_train, n_topics_best, portion_back=portion_back,\n",
    "                                  tau_back=tau_back_best, tau_decor=tau_decor)\n",
    "    parameters['cls'] = cls_name_best\n",
    "    f1 = classify(model, bv_train, bv_val, name_to_cls[cls_name_best], train_target, val_target)\n",
    "    top_tokens = model.score_tracker['top-tokens'].last_tokens\n",
    "    result = {'parameters': parameters,\n",
    "              'perplexity': model.score_tracker[\"perplexity\"].value,\n",
    "              'sparsity': model.score_tracker[\"sparsity\"].value,\n",
    "              'top-tokens': [top_tokens[topic_name] for topic_name in model.topic_names],\n",
    "              'f1': f1}\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{results_dir}/result_decor.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparsification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_decor_best = 1e5\n",
    "\n",
    "results = []\n",
    "grid = product(portions_back, taus_sparse)\n",
    "for portion_back, tau_sparse in tqdm(grid):\n",
    "    model, parameters = get_model(bv_train, n_topics_best, portion_back=portion_back,\n",
    "                                  tau_back=tau_back_best, tau_decor=tau_decor_best, tau_sparse=tau_sparse)\n",
    "    parameters['cls'] = cls_name_best\n",
    "    f1 = classify(model, bv_train, bv_val, name_to_cls[cls_name_best], train_target, val_target)\n",
    "    top_tokens = model.score_tracker['top-tokens'].last_tokens\n",
    "    result = {'parameters': parameters,\n",
    "              'perplexity': model.score_tracker[\"perplexity\"].value,\n",
    "              'sparsity': model.score_tracker[\"sparsity\"].value,\n",
    "              'top-tokens': [top_tokens[topic_name] for topic_name in model.topic_names],\n",
    "              'f1': f1}\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{results_dir}/result_decor.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.19921025641025641\n",
      "10 0.19923076923076924\n",
      "10 0.19924102564102564\n",
      "10 0.19923589743589742\n",
      "100.0 0.1992205128205128\n",
      "100.0 0.19924615384615385\n",
      "100.0 0.1992205128205128\n"
     ]
    }
   ],
   "source": [
    "results\n",
    "for res in results:\n",
    "    print(res['parameters']['tau_back'], res['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [03:59, 239.03s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "grid = product([10], ['LogReg'], [100000], [0.2])\n",
    "for n_topics, cls_name, tau_back, portion_back in tqdm(grid):\n",
    "    model, parameters = get_model(bv_train, n_topics, portion_back=portion_back, tau_back=tau_back)\n",
    "    parameters['cls'] = cls_name\n",
    "    f1 = classify(model, bv_train, bv_val, name_to_cls[cls_name], train_target, val_target)\n",
    "    top_tokens = model.score_tracker['top-tokens'].last_tokens\n",
    "    result = {'parameters': parameters,\n",
    "              'perplexity': model.score_tracker[\"perplexity\"].value,\n",
    "              'sparsity': model.score_tracker[\"sparsity\"].value,\n",
    "              'top-tokens': [top_tokens[topic_name] for topic_name in model.topic_names],\n",
    "              'f1': f1}\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19934871794871795"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1994974358974359"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1994974358974359"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [05:44, 172.43s/it]\n"
     ]
    }
   ],
   "source": [
    "grid = product(N_topics, taus_portions_back, taus_sparse_decor)\n",
    "results_dir = 'results'\n",
    "\n",
    "it = 0\n",
    "for n_topics, tau_portion_back, tau_sparse_decor in tqdm(grid):\n",
    "    if it > 0:\n",
    "        break\n",
    "    \n",
    "    tau_back, portion_back = tau_portion_back\n",
    "    tau_sparse, tau_decor = tau_sparse_decor\n",
    "    if tau_decor == 1e5:\n",
    "        model = get_model(bv, n_topics, portion_back, tau_back, tau_sparse, tau_decor)\n",
    "\n",
    "        parameters = {'n_topics': n_topics, 'portion_back': portion_back, 'tau_back': tau_back,\n",
    "                      'tau_sparse': tau_sparse, 'tau_decor': tau_decor}\n",
    "        result = {'parameters': parameters, 'perplexity': [], 'sparsity': []}\n",
    "        for i in range(20):\n",
    "            model.fit_offline(bv, num_collection_passes=1)\n",
    "            perplexity = model.score_tracker[\"perplexity\"].last_value\n",
    "            sparsity = model.score_tracker[\"sparsity\"].last_value\n",
    "            result['perplexity'].append(perplexity)\n",
    "            result['sparsity'].append(sparsity)\n",
    "\n",
    "        top_tokens = model.score_tracker['top-tokens'].last_tokens\n",
    "        result['top-tokens'] = [top_tokens[topic_name] for topic_name in model.topic_names]\n",
    "        result['theta'] = model.get_theta()\n",
    "\n",
    "        with open(f'{results_dir}/result_{it}.pickle', 'wb') as handle:\n",
    "            pickle.dump(result, handle)\n",
    "\n",
    "        it += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/result_19.pickle', 'rb') as handle:\n",
    "    result = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESCRIPTION: {'n_topics': 10, 'portion_back': 0.1, 'tau_back': 10, 'tau_sparse': 10, 'tau_decor': 100000.0} \n",
      "\n",
      "PERPLEXITY: [313523.28125, 2586.058837890625, 2566.08154296875, 2519.09130859375, 2464.9404296875, 2401.533447265625, 2320.0224609375, 2236.3779296875, 2164.45263671875, 2106.490966796875, 2060.423095703125, 2023.589599609375, 1993.7294921875, 1969.31689453125, 1949.295166015625, 1932.7796630859375, 1919.019287109375, 1907.3822021484375, 1897.428466796875, 1888.8182373046875] \n",
      "\n",
      "SPARSITY: [1.5655576817152905e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] \n",
      "\n",
      "TOP TOKENS: [['room', 'stay', 'hotel', 'vegas', 'strip', 'night', 'free', 'like', 'clean', 'nice'], ['hour', 'happy', 'service', 'look', 'close', 'new', 'amazing', 'year', 'time', 'hair'], ['tell', 'call', 'take', 'time', 'say', 'show', 'customer', 'ask', 'work', 'car'], ['place', 'drink', 'bar', 'pretty', 'friend', 'beer', 'people', 'see', 'nice', 'night'], ['chicken', 'burger', 'sauce', 'order', 'eat', 'like', 'dish', 'fries', 'roll', 'sushi'], ['pizza', 'order', 'cheese', 'star', 'small', 'two', 'give', 'want', 'think', 'eat'], ['food', 'service', 'restaurant', 'menu', 'time', 'table', 'meal', 'nothing', 'taco', 'seat'], ['come', 'place', 'order', 'say', 'wait', 'like', 'take', 'minute', 'make', 'time'], ['little', 'buffet', 'breakfast', 'coffee', 'dessert', 'like', 'cream', 'ice', 'worth', 'try'], ['find', 'store', 'location', 'like', 'price', 'love', 'look', 'shop', 'need', 'well']]\n"
     ]
    }
   ],
   "source": [
    "print(\"DESCRIPTION:\", result['parameters'], '\\n')\n",
    "print(\"PERPLEXITY:\", result['perplexity'], '\\n')\n",
    "print(\"SPARSITY:\", result['sparsity'], '\\n')\n",
    "print(\"TOP TOKENS:\", result['top-tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>170000</th>\n",
       "      <th>170001</th>\n",
       "      <th>170002</th>\n",
       "      <th>170003</th>\n",
       "      <th>170004</th>\n",
       "      <th>170005</th>\n",
       "      <th>170006</th>\n",
       "      <th>170007</th>\n",
       "      <th>170008</th>\n",
       "      <th>170009</th>\n",
       "      <th>...</th>\n",
       "      <th>309990</th>\n",
       "      <th>309991</th>\n",
       "      <th>309992</th>\n",
       "      <th>309993</th>\n",
       "      <th>309994</th>\n",
       "      <th>309995</th>\n",
       "      <th>309996</th>\n",
       "      <th>309997</th>\n",
       "      <th>309998</th>\n",
       "      <th>309999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic_0</th>\n",
       "      <td>0.283193</td>\n",
       "      <td>0.452112</td>\n",
       "      <td>0.535925</td>\n",
       "      <td>0.527817</td>\n",
       "      <td>0.323818</td>\n",
       "      <td>0.531445</td>\n",
       "      <td>0.286066</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>0.643041</td>\n",
       "      <td>0.496274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>0.074090</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.049669</td>\n",
       "      <td>0.075123</td>\n",
       "      <td>0.050898</td>\n",
       "      <td>0.081712</td>\n",
       "      <td>0.055124</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>0.021841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_1</th>\n",
       "      <td>0.036622</td>\n",
       "      <td>0.024368</td>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.024586</td>\n",
       "      <td>0.124620</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.042648</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.109974</td>\n",
       "      <td>0.017760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016777</td>\n",
       "      <td>0.054202</td>\n",
       "      <td>0.069354</td>\n",
       "      <td>0.161219</td>\n",
       "      <td>0.023809</td>\n",
       "      <td>0.089995</td>\n",
       "      <td>0.122173</td>\n",
       "      <td>0.056652</td>\n",
       "      <td>0.059645</td>\n",
       "      <td>0.493905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_2</th>\n",
       "      <td>0.451766</td>\n",
       "      <td>0.161228</td>\n",
       "      <td>0.097932</td>\n",
       "      <td>0.259569</td>\n",
       "      <td>0.176654</td>\n",
       "      <td>0.257451</td>\n",
       "      <td>0.221406</td>\n",
       "      <td>0.067270</td>\n",
       "      <td>0.079154</td>\n",
       "      <td>0.156938</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107481</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>0.011835</td>\n",
       "      <td>0.120469</td>\n",
       "      <td>0.073937</td>\n",
       "      <td>0.030360</td>\n",
       "      <td>0.023972</td>\n",
       "      <td>0.007985</td>\n",
       "      <td>0.030518</td>\n",
       "      <td>0.000981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_3</th>\n",
       "      <td>0.020884</td>\n",
       "      <td>0.129450</td>\n",
       "      <td>0.030177</td>\n",
       "      <td>0.024625</td>\n",
       "      <td>0.035784</td>\n",
       "      <td>0.026901</td>\n",
       "      <td>0.110320</td>\n",
       "      <td>0.107800</td>\n",
       "      <td>0.023190</td>\n",
       "      <td>0.050897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.207455</td>\n",
       "      <td>0.485271</td>\n",
       "      <td>0.234376</td>\n",
       "      <td>0.174788</td>\n",
       "      <td>0.071596</td>\n",
       "      <td>0.172209</td>\n",
       "      <td>0.123435</td>\n",
       "      <td>0.046908</td>\n",
       "      <td>0.029192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_4</th>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.020607</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.007266</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>0.018596</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029963</td>\n",
       "      <td>0.030909</td>\n",
       "      <td>0.025642</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.038294</td>\n",
       "      <td>0.108599</td>\n",
       "      <td>0.023267</td>\n",
       "      <td>0.311536</td>\n",
       "      <td>0.094413</td>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_5</th>\n",
       "      <td>0.032310</td>\n",
       "      <td>0.035904</td>\n",
       "      <td>0.080640</td>\n",
       "      <td>0.031049</td>\n",
       "      <td>0.075946</td>\n",
       "      <td>0.041965</td>\n",
       "      <td>0.086160</td>\n",
       "      <td>0.048664</td>\n",
       "      <td>0.019274</td>\n",
       "      <td>0.066993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059488</td>\n",
       "      <td>0.144536</td>\n",
       "      <td>0.064304</td>\n",
       "      <td>0.096982</td>\n",
       "      <td>0.141458</td>\n",
       "      <td>0.278575</td>\n",
       "      <td>0.122423</td>\n",
       "      <td>0.224799</td>\n",
       "      <td>0.205001</td>\n",
       "      <td>0.002025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_6</th>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.051616</td>\n",
       "      <td>0.024404</td>\n",
       "      <td>0.018118</td>\n",
       "      <td>0.020623</td>\n",
       "      <td>0.011219</td>\n",
       "      <td>0.036221</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.014555</td>\n",
       "      <td>0.068468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261162</td>\n",
       "      <td>0.122658</td>\n",
       "      <td>0.058844</td>\n",
       "      <td>0.076232</td>\n",
       "      <td>0.177268</td>\n",
       "      <td>0.128072</td>\n",
       "      <td>0.194790</td>\n",
       "      <td>0.046678</td>\n",
       "      <td>0.104923</td>\n",
       "      <td>0.391717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_7</th>\n",
       "      <td>0.117682</td>\n",
       "      <td>0.010071</td>\n",
       "      <td>0.101362</td>\n",
       "      <td>0.039891</td>\n",
       "      <td>0.152872</td>\n",
       "      <td>0.056085</td>\n",
       "      <td>0.144950</td>\n",
       "      <td>0.060892</td>\n",
       "      <td>0.102403</td>\n",
       "      <td>0.054753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491154</td>\n",
       "      <td>0.083728</td>\n",
       "      <td>0.034596</td>\n",
       "      <td>0.151471</td>\n",
       "      <td>0.146786</td>\n",
       "      <td>0.059765</td>\n",
       "      <td>0.116745</td>\n",
       "      <td>0.015168</td>\n",
       "      <td>0.137073</td>\n",
       "      <td>0.008049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_8</th>\n",
       "      <td>0.006392</td>\n",
       "      <td>0.058913</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.006659</td>\n",
       "      <td>0.036755</td>\n",
       "      <td>0.004844</td>\n",
       "      <td>0.032254</td>\n",
       "      <td>0.027665</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>0.028911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.064684</td>\n",
       "      <td>0.044830</td>\n",
       "      <td>0.010017</td>\n",
       "      <td>0.045030</td>\n",
       "      <td>0.085397</td>\n",
       "      <td>0.121991</td>\n",
       "      <td>0.102583</td>\n",
       "      <td>0.173336</td>\n",
       "      <td>0.016278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_9</th>\n",
       "      <td>0.022017</td>\n",
       "      <td>0.055731</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.066625</td>\n",
       "      <td>0.045662</td>\n",
       "      <td>0.050635</td>\n",
       "      <td>0.021378</td>\n",
       "      <td>0.081481</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.050248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.129244</td>\n",
       "      <td>0.166069</td>\n",
       "      <td>0.096192</td>\n",
       "      <td>0.103506</td>\n",
       "      <td>0.096742</td>\n",
       "      <td>0.020718</td>\n",
       "      <td>0.056039</td>\n",
       "      <td>0.144814</td>\n",
       "      <td>0.034540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  650000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           170000    170001    170002    170003    170004    170005    170006  \\\n",
       "topic_0  0.283193  0.452112  0.535925  0.527817  0.323818  0.531445  0.286066   \n",
       "topic_1  0.036622  0.024368  0.040415  0.024586  0.124620  0.010490  0.042648   \n",
       "topic_2  0.451766  0.161228  0.097932  0.259569  0.176654  0.257451  0.221406   \n",
       "topic_3  0.020884  0.129450  0.030177  0.024625  0.035784  0.026901  0.110320   \n",
       "topic_4  0.002980  0.020607  0.002391  0.001061  0.007266  0.008965  0.018596   \n",
       "topic_5  0.032310  0.035904  0.080640  0.031049  0.075946  0.041965  0.086160   \n",
       "topic_6  0.026154  0.051616  0.024404  0.018118  0.020623  0.011219  0.036221   \n",
       "topic_7  0.117682  0.010071  0.101362  0.039891  0.152872  0.056085  0.144950   \n",
       "topic_8  0.006392  0.058913  0.010563  0.006659  0.036755  0.004844  0.032254   \n",
       "topic_9  0.022017  0.055731  0.076190  0.066625  0.045662  0.050635  0.021378   \n",
       "\n",
       "           170007    170008    170009  ...    309990    309991    309992  \\\n",
       "topic_0  0.568600  0.643041  0.496274  ...  0.016361  0.074090  0.039254   \n",
       "topic_1  0.015200  0.109974  0.017760  ...  0.016777  0.054202  0.069354   \n",
       "topic_2  0.067270  0.079154  0.156938  ...  0.107481  0.088496  0.011835   \n",
       "topic_3  0.107800  0.023190  0.050897  ...  0.008145  0.207455  0.485271   \n",
       "topic_4  0.006807  0.002893  0.008758  ...  0.029963  0.030909  0.025642   \n",
       "topic_5  0.048664  0.019274  0.066993  ...  0.059488  0.144536  0.064304   \n",
       "topic_6  0.015619  0.014555  0.068468  ...  0.261162  0.122658  0.058844   \n",
       "topic_7  0.060892  0.102403  0.054753  ...  0.491154  0.083728  0.034596   \n",
       "topic_8  0.027665  0.002442  0.028911  ...  0.004025  0.064684  0.044830   \n",
       "topic_9  0.081481  0.003074  0.050248  ...  0.005445  0.129244  0.166069   \n",
       "\n",
       "           309993    309994    309995    309996    309997    309998    309999  \n",
       "topic_0  0.049669  0.075123  0.050898  0.081712  0.055124  0.003368  0.021841  \n",
       "topic_1  0.161219  0.023809  0.089995  0.122173  0.056652  0.059645  0.493905  \n",
       "topic_2  0.120469  0.073937  0.030360  0.023972  0.007985  0.030518  0.000981  \n",
       "topic_3  0.234376  0.174788  0.071596  0.172209  0.123435  0.046908  0.029192  \n",
       "topic_4  0.003373  0.038294  0.108599  0.023267  0.311536  0.094413  0.001472  \n",
       "topic_5  0.096982  0.141458  0.278575  0.122423  0.224799  0.205001  0.002025  \n",
       "topic_6  0.076232  0.177268  0.128072  0.194790  0.046678  0.104923  0.391717  \n",
       "topic_7  0.151471  0.146786  0.059765  0.116745  0.015168  0.137073  0.008049  \n",
       "topic_8  0.010017  0.045030  0.085397  0.121991  0.102583  0.173336  0.016278  \n",
       "topic_9  0.096192  0.103506  0.096742  0.020718  0.056039  0.144814  0.034540  \n",
       "\n",
       "[10 rows x 650000 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['theta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}